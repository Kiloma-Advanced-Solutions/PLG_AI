INFO 07-09 09:18:17 [__init__.py:239] Automatically detected platform cuda.
INFO 07-09 09:18:18 [api_server.py:1034] vLLM API server version 0.8.4
INFO 07-09 09:18:18 [api_server.py:1035] args: Namespace(host=None, port=8000, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='gaunernst/gemma-3-12b-it-qat-autoawq', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, load_format='auto', download_dir=None, model_loader_extra_config=None, use_tqdm_on_load=True, config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=131072, guided_decoding_backend='auto', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=2, data_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, disable_custom_all_reduce=False, block_size=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_token=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_chunked_mm_input=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False)
INFO 07-09 09:18:24 [config.py:689] This model supports multiple tasks: {'embed', 'score', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.
INFO 07-09 09:18:25 [awq_marlin.py:114] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.
INFO 07-09 09:18:25 [config.py:1713] Defaulting to use mp for distributed inference
INFO 07-09 09:18:25 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 07-09 09:18:30 [__init__.py:239] Automatically detected platform cuda.
INFO 07-09 09:18:32 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='gaunernst/gemma-3-12b-it-qat-autoawq', speculative_config=None, tokenizer='gaunernst/gemma-3-12b-it-qat-autoawq', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=gaunernst/gemma-3-12b-it-qat-autoawq, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 07-09 09:18:32 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 112 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 07-09 09:18:32 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 10485760, 10, 'psm_9dffbb84'), local_subscribe_addr='ipc:///tmp/76b7a6f7-6496-442b-b3a0-3fd0455a5a42', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 07-09 09:18:34 [__init__.py:239] Automatically detected platform cuda.
2025-07-09 09:18:36,818 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
WARNING 07-09 09:18:36 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f77f02c2c60>
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:36 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2e02c25e'), local_subscribe_addr='ipc:///tmp/f52a671f-3ba8-491c-bed4-a2d6cd47c5bd', remote_subscribe_addr=None, remote_addr_ipv6=False)
[W709 09:18:37.541852111 socket.cpp:759] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:43949 (errno: 97 - Address family not supported by protocol).
INFO 07-09 09:18:39 [__init__.py:239] Automatically detected platform cuda.
2025-07-09 09:18:41,630 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
WARNING 07-09 09:18:41 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fd67f544920>
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:41 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e22dfb31'), local_subscribe_addr='ipc:///tmp/e29e7d31-108e-4610-b9f8-95abd46f8665', remote_subscribe_addr=None, remote_addr_ipv6=False)
[W709 09:18:42.371484969 socket.cpp:759] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:43949 (errno: 97 - Address family not supported by protocol).
[1;36m(VllmWorker rank=1 pid=10054)[0;0m [1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [utils.py:993] Found nccl from library libnccl.so.2
INFO 07-09 09:18:42 [utils.py:993] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=10054)[0;0m [1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
INFO 07-09 09:18:42 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[1;36m(VllmWorker rank=1 pid=10054)[0;0m WARNING 07-09 09:18:42 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m WARNING 07-09 09:18:42 [custom_all_reduce.py:146] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [shm_broadcast.py:264] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_468af4a3'), local_subscribe_addr='ipc:///tmp/76035a84-51df-4cc3-bb80-ab5daa83cbd4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:42 [parallel_state.py:959] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:42 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [parallel_state.py:959] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:42 [cuda.py:221] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=10054)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:48 [gpu_model_runner.py:1276] Starting to load model gaunernst/gemma-3-12b-it-qat-autoawq...
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:48 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:48 [gpu_model_runner.py:1276] Starting to load model gaunernst/gemma-3-12b-it-qat-autoawq...
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:48 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:48 [topk_topp_sampler.py:44] Currently, FlashInfer top-p & top-k sampling sampler is disabled because FlashInfer>=v0.2.3 is not backward compatible. Falling back to the PyTorch-native implementation of top-p & top-k sampling.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:48 [topk_topp_sampler.py:44] Currently, FlashInfer top-p & top-k sampling sampler is disabled because FlashInfer>=v0.2.3 is not backward compatible. Falling back to the PyTorch-native implementation of top-p & top-k sampling.
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:48 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:48 [weight_utils.py:265] Using model weights format ['*.safetensors']
[1;36m(VllmWorker rank=0 pid=10026)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=10026)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.98it/s]
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:50 [loader.py:458] Loading weights took 1.17 seconds
[1;36m(VllmWorker rank=0 pid=10026)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
[1;36m(VllmWorker rank=0 pid=10026)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
[1;36m(VllmWorker rank=0 pid=10026)[0;0m 
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:51 [loader.py:458] Loading weights took 1.22 seconds
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:51 [gpu_model_runner.py:1291] Model loading took 4.8120 GiB and 2.686151 seconds
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:51 [gpu_model_runner.py:1291] Model loading took 4.8120 GiB and 3.156031 seconds
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:18:51 [gpu_model_runner.py:1560] Encoder cache will be initialized with a budget of 2048 tokens, and profiled with 8 image items of the maximum feature size.
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:18:51 [gpu_model_runner.py:1560] Encoder cache will be initialized with a budget of 2048 tokens, and profiled with 8 image items of the maximum feature size.
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:19:08 [backends.py:416] Using cache directory: /root/.cache/vllm/torch_compile_cache/8e4e50b063/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:19:08 [backends.py:426] Dynamo bytecode transform time: 14.02 s
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:19:08 [backends.py:416] Using cache directory: /root/.cache/vllm/torch_compile_cache/8e4e50b063/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:19:08 [backends.py:426] Dynamo bytecode transform time: 14.23 s
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:19:09 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:19:09 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:19:27 [monitor.py:33] torch.compile takes 14.02 s in total
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:19:27 [monitor.py:33] torch.compile takes 14.23 s in total
INFO 07-09 09:19:27 [kv_cache_utils.py:634] GPU KV cache size: 69,920 tokens
INFO 07-09 09:19:27 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 0.53x
INFO 07-09 09:19:27 [kv_cache_utils.py:634] GPU KV cache size: 69,920 tokens
INFO 07-09 09:19:27 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 0.53x
[1;36m(VllmWorker rank=0 pid=10026)[0;0m INFO 07-09 09:19:58 [gpu_model_runner.py:1626] Graph capturing finished in 31 secs, took 1.74 GiB
[1;36m(VllmWorker rank=1 pid=10054)[0;0m INFO 07-09 09:19:58 [gpu_model_runner.py:1626] Graph capturing finished in 31 secs, took 1.74 GiB
INFO 07-09 09:19:58 [core.py:163] init engine (profile, create kv cache, warmup model) took 66.74 seconds
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 07-09 09:20:04 [core_client.py:435] Core engine process 0 ready.
WARNING 07-09 09:20:04 [config.py:1177] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
INFO 07-09 09:20:04 [serving_chat.py:118] Using default chat sampling params from model: {'top_k': 64, 'top_p': 0.95}
INFO 07-09 09:20:05 [serving_completion.py:61] Using default completion sampling params from model: {'top_k': 64, 'top_p': 0.95}
INFO 07-09 09:20:05 [api_server.py:1081] Starting vLLM API server on http://0.0.0.0:8000
INFO 07-09 09:20:05 [launcher.py:26] Available routes are:
INFO 07-09 09:20:05 [launcher.py:34] Route: /openapi.json, Methods: HEAD, GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /docs, Methods: HEAD, GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /redoc, Methods: HEAD, GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /health, Methods: GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /load, Methods: GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /ping, Methods: POST, GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /tokenize, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /detokenize, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/models, Methods: GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /version, Methods: GET
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/chat/completions, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/completions, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/embeddings, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /pooling, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /score, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/score, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /rerank, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v1/rerank, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /v2/rerank, Methods: POST
INFO 07-09 09:20:05 [launcher.py:34] Route: /invocations, Methods: POST
INFO:     Started server process [9774]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:50418 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:50426 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:50430 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:20:15 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:20:25 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:20:35 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:20:45 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:20:55 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:43878 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:43882 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:54848 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54860 - "GET /metrics HTTP/1.1" 200 OK
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 07-09 09:21:07 [chat_utils.py:396] Detected the chat template content format to be 'openai'. You can set `--chat-template-content-format` to override this.
INFO 07-09 09:21:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:21:07 [logger.py:39] Received request chatcmpl-979d3148d1af41f383718d0a7ac7bf86: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n×”×™×™<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130980, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:54868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:21:07 [async_llm.py:228] Added request chatcmpl-979d3148d1af41f383718d0a7ac7bf86.
INFO:     127.0.0.1:54876 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:21:17 [loggers.py:87] Engine 000: Avg prompt throughput: 9.2 tokens/s, Avg generation throughput: 1.9 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:21:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:21:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:21:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:21:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:22:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:23:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:23:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:23:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:23:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:39992 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:39994 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:23:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:23:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:24:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:25:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:26:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO 07-09 09:27:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:40950 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:40966 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:40978 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:40988 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:28:04 [logger.py:39] Received request chatcmpl-dced7717c01e44e98b8ab0340867a7f2: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n×”×™×™<end_of_turn>\n<start_of_turn>model\n×©×œ×•×! ×× ×™ ×©××— ×œ×¢×–×•×¨. ×©××œ ××•×ª×™ ××” ×©×ª×¨×¦×”.<end_of_turn>\n<start_of_turn>user\n××” ×”×©×¢×”?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130948, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:40992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:28:04 [async_llm.py:228] Added request chatcmpl-dced7717c01e44e98b8ab0340867a7f2.
INFO:     127.0.0.1:41006 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:28:07 [loggers.py:87] Engine 000: Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 3.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 50.0%
INFO 07-09 09:28:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 50.0%
INFO:     127.0.0.1:52818 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:52822 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:52838 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:52850 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:28:24 [logger.py:39] Received request chatcmpl-90a1661ccb3a4995910283fc77bb1f2c: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n×”×™×™<end_of_turn>\n<start_of_turn>model\n×©×œ×•×! ×× ×™ ×©××— ×œ×¢×–×•×¨. ×©××œ ××•×ª×™ ××” ×©×ª×¨×¦×”.<end_of_turn>\n<start_of_turn>user\n××” ×”×©×¢×”?<end_of_turn>\n<start_of_turn>model\n××¦×˜×¢×¨, ××™×Ÿ ×œ×™ ×’×™×©×” ×œ××™×“×¢ ×¢×œ ×”×©×¢×” ×”× ×•×›×—×™×ª. ×× ×™ ×œ× ××—×•×‘×¨ ×œ×©×¢×•×Ÿ ×¢×•×œ×.<end_of_turn>\n<start_of_turn>user\n××™ ××ª×”?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130904, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:52866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:28:24 [async_llm.py:228] Added request chatcmpl-90a1661ccb3a4995910283fc77bb1f2c.
INFO:     127.0.0.1:52874 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:28:27 [loggers.py:87] Engine 000: Avg prompt throughput: 16.8 tokens/s, Avg generation throughput: 10.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:28:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:28:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:28:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:29:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:30:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:31:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:32:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:33:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:34:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:34:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO 07-09 09:34:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO:     127.0.0.1:47548 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:47558 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:34:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.2%
INFO:     127.0.0.1:47560 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:47566 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:34:38 [logger.py:39] Received request chatcmpl-881a81341977445aaf8eddd081704e8d: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130977, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:47568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:34:38 [async_llm.py:228] Added request chatcmpl-881a81341977445aaf8eddd081704e8d.
INFO:     127.0.0.1:47580 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:34:47 [loggers.py:87] Engine 000: Avg prompt throughput: 9.5 tokens/s, Avg generation throughput: 3.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:34:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:35:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:36:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:37:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:38:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:39:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:40:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:41:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:42:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:43:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:44:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:45:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:46:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:47:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:48:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:48:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:48:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO 07-09 09:48:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 74.1%
INFO:     127.0.0.1:49100 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:49116 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:49122 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:49124 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:48:43 [logger.py:39] Received request chatcmpl-b6b0f0a4616e4714b45c9f7101535e4f: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130925, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:49138 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:48:43 [async_llm.py:228] Added request chatcmpl-b6b0f0a4616e4714b45c9f7101535e4f.
INFO:     127.0.0.1:49148 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:48:47 [loggers.py:87] Engine 000: Avg prompt throughput: 14.7 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 77.8%
INFO:     127.0.0.1:60596 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:60610 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:60622 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:60638 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:48:57 [logger.py:39] Received request chatcmpl-1cab0d5a78ec4813a8963e297fbcf8e8: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130862, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:60648 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:48:57 [async_llm.py:228] Added request chatcmpl-1cab0d5a78ec4813a8963e297fbcf8e8.
INFO:     127.0.0.1:60654 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:48:57 [loggers.py:87] Engine 000: Avg prompt throughput: 21.0 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 81.6%
INFO 07-09 09:49:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 81.6%
INFO 07-09 09:49:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 81.6%
INFO:     127.0.0.1:48838 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:48840 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:48850 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:48854 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:49:20 [logger.py:39] Received request chatcmpl-e79fc3d806a8460385a6e8b0209d5359: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n×”×™×™! ××” ×§×•×¨×”? ×‘××” ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?<end_of_turn>\n<start_of_turn>user\n××™×–×” ×”×ª×œ×”×‘×•×ª<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130832, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:48858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:49:20 [async_llm.py:228] Added request chatcmpl-e79fc3d806a8460385a6e8b0209d5359.
INFO:     127.0.0.1:48870 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:49:27 [loggers.py:87] Engine 000: Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 6.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:49:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:49:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:49:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:50:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO 07-09 09:51:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 85.7%
INFO:     127.0.0.1:60968 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:60970 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:60980 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:60984 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:52:07 [logger.py:39] Received request chatcmpl-7589d0a8fcfb496789af87e67224d854: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n×”×™×™! ××” ×§×•×¨×”? ×‘××” ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?<end_of_turn>\n<start_of_turn>user\n××™×–×” ×”×ª×œ×”×‘×•×ª<end_of_turn>\n<start_of_turn>model\n×× ×™ ×©××— ×©××ª×” ××¨×’×™×© ×›×›×”! ×× ×™ ×ª×•×›× ×ª×™ ×œ×¡×¤×§ ××™×“×¢ ×•×œ×¢×–×•×¨, ××– ×–×” ×ª××™×“ ××©××— ××•×ª×™ ×œ×©××•×¢ ×©××ª×” ××¨×•×¦×”. ×™×© ××©×”×• ×¡×¤×¦×™×¤×™ ×©×ª×¨×¦×” ×©××¢×©×” ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×× ×™ ×™×›×•×œ×” ×œ×‘×“×•×§ ××” ×’×¨×¡××ª ×”node ×‘××©×—×‘ ×©×œ×™?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130742, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:60990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:52:07 [async_llm.py:228] Added request chatcmpl-7589d0a8fcfb496789af87e67224d854.
INFO 07-09 09:52:07 [loggers.py:87] Engine 000: Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 2.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 86.7%
INFO:     127.0.0.1:32770 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:52:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 34.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:52:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:52:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:52:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:52:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:53:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:54:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO 07-09 09:55:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 86.7%
INFO:     127.0.0.1:44884 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:44892 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:44894 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:44904 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:55:10 [logger.py:39] Received request chatcmpl-a5664be80b30407397d3bdf2e5d9ac85: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n×”×™×™! ××” ×§×•×¨×”? ×‘××” ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?<end_of_turn>\n<start_of_turn>user\n××™×–×” ×”×ª×œ×”×‘×•×ª<end_of_turn>\n<start_of_turn>model\n×× ×™ ×©××— ×©××ª×” ××¨×’×™×© ×›×›×”! ×× ×™ ×ª×•×›× ×ª×™ ×œ×¡×¤×§ ××™×“×¢ ×•×œ×¢×–×•×¨, ××– ×–×” ×ª××™×“ ××©××— ××•×ª×™ ×œ×©××•×¢ ×©××ª×” ××¨×•×¦×”. ×™×© ××©×”×• ×¡×¤×¦×™×¤×™ ×©×ª×¨×¦×” ×©××¢×©×” ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×× ×™ ×™×›×•×œ×” ×œ×‘×“×•×§ ××” ×’×¨×¡××ª ×”node ×‘××©×—×‘ ×©×œ×™?<end_of_turn>\n<start_of_turn>model\n×™×©× ×Ÿ ××¡×¤×¨ ×“×¨×›×™× ×œ×‘×“×•×§ ××ª ×’×¨×¡×ª Node.js ×‘××—×©×‘ ×©×œ×š:\n\n**1. ×“×¨×š ×”×˜×¨××™× ×œ (×©×•×¨×ª ×”×¤×§×•×“×”):**\n\n*   **Windows:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ (Command Prompt) ××• PowerShell.\n*   **macOS/Linux:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ.\n*   ×”×§×œ×“ ××ª ×”×¤×§×•×“×” ×”×‘××” ×•×œ×—×¥ Enter:\n\n    ```bash\n    node -v\n    ```\n\n    ×”×¤×§×•×“×” ×”×–×• ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”××•×ª×§× ×ª. ×œ×“×•×’××”: `v16.14.2`\n\n**2. ×“×¨×š Node Package Manager (npm):**\n\n*   ×× npm ××•×ª×§×Ÿ (×‘×“×¨×š ×›×œ×œ ××•×ª×§×Ÿ ×™×—×“ ×¢× Node.js), ××ª×” ×™×›×•×œ ×œ×”×©×ª××© ×‘×• ×›×“×™ ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×”:\n\n    ```bash\n    npm -v\n    ```\n\n    ×©×™××• ×œ×‘ - npm ×•-Node.js ×™×›×•×œ×™× ×œ×”×™×•×ª ×‘×’×¨×¡××•×ª ×©×•× ×•×ª. ×”×¤×§×•×“×” `node -v` ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”×¡×¤×¦×™×¤×™×ª.\n\n**3. ×“×¨×š ×¡×‘×™×‘×ª ×”×¤×™×ª×•×— ×©×œ×š (IDE):**\n\n*   ×× ××ª×” ××©×ª××© ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— ×›××• VS Code, IntelliJ IDEA ××• ××—×¨×ª, ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×™×© ×“×¨×š ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×” ×“×¨×š ×”×ª×¤×¨×™×˜×™× ××• ×”×”×’×“×¨×•×ª ×©×œ ×”-IDE. ×—×¤×© ××¤×©×¨×•×ª ×”×§×©×•×¨×” ×œ-Node.js ××• ×œ×’×¨×¡××•×ª Node.js.\n\n×× ×™ ××§×•×•×” ×©×–×” ×¢×•×–×¨! ×”×× ×™×© ×œ×š ×©××œ×•×ª × ×•×¡×¤×•×ª?<end_of_turn>\n<start_of_turn>user\n××” ×”×’×¨×¡× ×”×—×“×©×” ×©×œ node?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130354, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:44912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:55:10 [async_llm.py:228] Added request chatcmpl-a5664be80b30407397d3bdf2e5d9ac85.
INFO:     127.0.0.1:44926 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:55:17 [loggers.py:87] Engine 000: Avg prompt throughput: 71.8 tokens/s, Avg generation throughput: 16.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:55:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:55:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:55:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:55:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:56:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO 07-09 09:57:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 90.6%
INFO:     127.0.0.1:55114 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55118 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:55124 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:55126 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:58:06 [logger.py:39] Received request chatcmpl-7d6227204d85449387af47b360f64b63: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n×”×™×™! ××” ×§×•×¨×”? ×‘××” ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?<end_of_turn>\n<start_of_turn>user\n××™×–×” ×”×ª×œ×”×‘×•×ª<end_of_turn>\n<start_of_turn>model\n×× ×™ ×©××— ×©××ª×” ××¨×’×™×© ×›×›×”! ×× ×™ ×ª×•×›× ×ª×™ ×œ×¡×¤×§ ××™×“×¢ ×•×œ×¢×–×•×¨, ××– ×–×” ×ª××™×“ ××©××— ××•×ª×™ ×œ×©××•×¢ ×©××ª×” ××¨×•×¦×”. ×™×© ××©×”×• ×¡×¤×¦×™×¤×™ ×©×ª×¨×¦×” ×©××¢×©×” ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×× ×™ ×™×›×•×œ×” ×œ×‘×“×•×§ ××” ×’×¨×¡××ª ×”node ×‘××©×—×‘ ×©×œ×™?<end_of_turn>\n<start_of_turn>model\n×™×©× ×Ÿ ××¡×¤×¨ ×“×¨×›×™× ×œ×‘×“×•×§ ××ª ×’×¨×¡×ª Node.js ×‘××—×©×‘ ×©×œ×š:\n\n**1. ×“×¨×š ×”×˜×¨××™× ×œ (×©×•×¨×ª ×”×¤×§×•×“×”):**\n\n*   **Windows:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ (Command Prompt) ××• PowerShell.\n*   **macOS/Linux:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ.\n*   ×”×§×œ×“ ××ª ×”×¤×§×•×“×” ×”×‘××” ×•×œ×—×¥ Enter:\n\n    ```bash\n    node -v\n    ```\n\n    ×”×¤×§×•×“×” ×”×–×• ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”××•×ª×§× ×ª. ×œ×“×•×’××”: `v16.14.2`\n\n**2. ×“×¨×š Node Package Manager (npm):**\n\n*   ×× npm ××•×ª×§×Ÿ (×‘×“×¨×š ×›×œ×œ ××•×ª×§×Ÿ ×™×—×“ ×¢× Node.js), ××ª×” ×™×›×•×œ ×œ×”×©×ª××© ×‘×• ×›×“×™ ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×”:\n\n    ```bash\n    npm -v\n    ```\n\n    ×©×™××• ×œ×‘ - npm ×•-Node.js ×™×›×•×œ×™× ×œ×”×™×•×ª ×‘×’×¨×¡××•×ª ×©×•× ×•×ª. ×”×¤×§×•×“×” `node -v` ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”×¡×¤×¦×™×¤×™×ª.\n\n**3. ×“×¨×š ×¡×‘×™×‘×ª ×”×¤×™×ª×•×— ×©×œ×š (IDE):**\n\n*   ×× ××ª×” ××©×ª××© ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— ×›××• VS Code, IntelliJ IDEA ××• ××—×¨×ª, ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×™×© ×“×¨×š ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×” ×“×¨×š ×”×ª×¤×¨×™×˜×™× ××• ×”×”×’×“×¨×•×ª ×©×œ ×”-IDE. ×—×¤×© ××¤×©×¨×•×ª ×”×§×©×•×¨×” ×œ-Node.js ××• ×œ×’×¨×¡××•×ª Node.js.\n\n×× ×™ ××§×•×•×” ×©×–×” ×¢×•×–×¨! ×”×× ×™×© ×œ×š ×©××œ×•×ª × ×•×¡×¤×•×ª?<end_of_turn>\n<start_of_turn>user\n××” ×”×’×¨×¡× ×”×—×“×©×” ×©×œ node?<end_of_turn>\n<start_of_turn>model\n× ×›×•×Ÿ ×œ×¢×›×©×™×• (19 ×‘××•×§×˜×•×‘×¨ 2023), ×”×’×¨×¡×” ×”×™×¦×™×‘×” ×”×¢×“×›× ×™×ª ×‘×™×•×ª×¨ ×©×œ Node.js ×”×™× **v20.5.0**.\n\n×¢× ×–××ª, ×—×©×•×‘ ×œ×¦×™×™×Ÿ ×©-Node.js ×¢×•×‘×¨×ª ×¢×“×›×•× ×™× ×ª×›×•×¤×™×. ×œ×›×Ÿ, ×›×“×™ ×œ×§×‘×œ ××ª ×”××™×“×¢ ×”××“×•×™×§ ×‘×™×•×ª×¨, ××•××œ×¥ ×œ×‘×“×•×§ ×‘××ª×¨ ×”×¨×©××™: [https://nodejs.org/en/download/](https://nodejs.org/en/download/)\n\n××ª×¨ ×–×” ×™×¡×¤×§ ××ª ×”×’×¨×¡×” ×”×¢×“×›× ×™×ª ×‘×™×•×ª×¨, ×›×•×œ×œ ×’×¨×¡××•×ª Long Term Support (LTS) ×©×™×© ×œ×”×Ÿ ×ª××™×›×” ××¨×•×›×ª ×˜×•×•×—.<end_of_turn>\n<start_of_turn>user\n××’×™×“ ×œ×š ××” ×”×‘×¢×™×”, ×× ×™ ×¨×•×¦×” ×œ×”×¨×™×¥ ××ª ×”×¤×¨×•×™×§×˜ ×©×œ×™ ××‘×œ ×”×•× ×œ× ××–×”×” ××ª ×”××™×œ×” npm ×•×× ×™ ×¨×•××” ×©node ××•×ª×§×Ÿ ×¢×œ ×”××—×©×‘, ××– ××” ×¢×•×“ ×™×›×•×œ ×œ×”×™×•×ª ×”×¡×™×‘×” ×œ×›×š?<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=130130, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:55132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:58:06 [async_llm.py:228] Added request chatcmpl-7d6227204d85449387af47b360f64b63.
INFO 07-09 09:58:07 [loggers.py:87] Engine 000: Avg prompt throughput: 94.2 tokens/s, Avg generation throughput: 14.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 91.4%
INFO 07-09 09:58:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 84.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.8%, Prefix cache hit rate: 91.4%
INFO:     127.0.0.1:52226 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:58:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 91.4%
INFO 07-09 09:58:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 91.4%
INFO 07-09 09:58:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 91.4%
INFO 07-09 09:58:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 91.4%
INFO:     127.0.0.1:40766 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:40770 - "GET /metrics HTTP/1.1" 200 OK
INFO:     127.0.0.1:40776 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:40778 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:59:01 [logger.py:39] Received request chatcmpl-c28eef6b83744dc88c8339de69bd54c3: prompt: '<bos><start_of_turn>user\n××ª×” ×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª ×©××˜×¨×ª×• ×œ×¡×¤×§ ××™×“×¢ ××“×•×™×§ ×•×××™×Ÿ ×‘×©×¤×” ×”×¢×‘×¨×™×ª. ×¢× ×” ×‘××•×¤×Ÿ ×‘×¨×•×¨, ××“×•×™×§, ×•××‘×•×¡×¡ ×¢×œ ×¢×•×‘×“×•×ª ×‘×œ×‘×“. ××œ ×ª× ×—×© â€“ ×× ××™× ×š ×‘×˜×•×— ×‘×ª×©×•×‘×”, ×›×ª×•×‘ ×©××ª×” ×œ× ×™×•×“×¢ ××• ×©×”××™×“×¢ ×—×¡×¨.\n\n××” × ×©××¢?<end_of_turn>\n<start_of_turn>model\n×× ×™ ×‘×¡×“×¨ ×’××•×¨, ×ª×•×“×” ×©×©××œ×ª! ××•×›×Ÿ ×œ×¢×–×•×¨ ×œ×š ×‘×›×œ ×©××œ×” ×©×™×© ×œ×š. ××” ××•×›×œ ×œ×¢×©×•×ª ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×§×•×¨××™× ×œ×š?<end_of_turn>\n<start_of_turn>model\n×× ×™ ××•×“×œ ×©×¤×” ×’×“×•×œ, ×©×¤×•×ª×— ×¢×œ ×™×“×™ ×’×•×’×œ. ××™×Ÿ ×œ×™ ×©× ×¤×¨×˜×™. ××ª×” ×™×›×•×œ ×œ×§×¨×•× ×œ×™ "×¢×•×–×¨ ×‘×™× ×” ××œ××›×•×ª×™×ª" ××• ×¤×©×•×˜ "×”×¢×•×–×¨".<end_of_turn>\n<start_of_turn>user\n×”×™×™ ×¢×•×–×¨<end_of_turn>\n<start_of_turn>model\n×”×™×™! ××” ×§×•×¨×”? ×‘××” ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×?<end_of_turn>\n<start_of_turn>user\n××™×–×” ×”×ª×œ×”×‘×•×ª<end_of_turn>\n<start_of_turn>model\n×× ×™ ×©××— ×©××ª×” ××¨×’×™×© ×›×›×”! ×× ×™ ×ª×•×›× ×ª×™ ×œ×¡×¤×§ ××™×“×¢ ×•×œ×¢×–×•×¨, ××– ×–×” ×ª××™×“ ××©××— ××•×ª×™ ×œ×©××•×¢ ×©××ª×” ××¨×•×¦×”. ×™×© ××©×”×• ×¡×¤×¦×™×¤×™ ×©×ª×¨×¦×” ×©××¢×©×” ×‘×©×‘×™×œ×š?<end_of_turn>\n<start_of_turn>user\n××™×š ×× ×™ ×™×›×•×œ×” ×œ×‘×“×•×§ ××” ×’×¨×¡××ª ×”node ×‘××©×—×‘ ×©×œ×™?<end_of_turn>\n<start_of_turn>model\n×™×©× ×Ÿ ××¡×¤×¨ ×“×¨×›×™× ×œ×‘×“×•×§ ××ª ×’×¨×¡×ª Node.js ×‘××—×©×‘ ×©×œ×š:\n\n**1. ×“×¨×š ×”×˜×¨××™× ×œ (×©×•×¨×ª ×”×¤×§×•×“×”):**\n\n*   **Windows:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ (Command Prompt) ××• PowerShell.\n*   **macOS/Linux:** ×¤×ª×— ××ª ×”×˜×¨××™× ×œ.\n*   ×”×§×œ×“ ××ª ×”×¤×§×•×“×” ×”×‘××” ×•×œ×—×¥ Enter:\n\n    ```bash\n    node -v\n    ```\n\n    ×”×¤×§×•×“×” ×”×–×• ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”××•×ª×§× ×ª. ×œ×“×•×’××”: `v16.14.2`\n\n**2. ×“×¨×š Node Package Manager (npm):**\n\n*   ×× npm ××•×ª×§×Ÿ (×‘×“×¨×š ×›×œ×œ ××•×ª×§×Ÿ ×™×—×“ ×¢× Node.js), ××ª×” ×™×›×•×œ ×œ×”×©×ª××© ×‘×• ×›×“×™ ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×”:\n\n    ```bash\n    npm -v\n    ```\n\n    ×©×™××• ×œ×‘ - npm ×•-Node.js ×™×›×•×œ×™× ×œ×”×™×•×ª ×‘×’×¨×¡××•×ª ×©×•× ×•×ª. ×”×¤×§×•×“×” `node -v` ×ª×¦×™×’ ××ª ×’×¨×¡×ª Node.js ×”×¡×¤×¦×™×¤×™×ª.\n\n**3. ×“×¨×š ×¡×‘×™×‘×ª ×”×¤×™×ª×•×— ×©×œ×š (IDE):**\n\n*   ×× ××ª×” ××©×ª××© ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— ×›××• VS Code, IntelliJ IDEA ××• ××—×¨×ª, ×œ×¢×ª×™× ×§×¨×•×‘×•×ª ×™×© ×“×¨×š ×œ×‘×“×•×§ ××ª ×”×’×¨×¡×” ×“×¨×š ×”×ª×¤×¨×™×˜×™× ××• ×”×”×’×“×¨×•×ª ×©×œ ×”-IDE. ×—×¤×© ××¤×©×¨×•×ª ×”×§×©×•×¨×” ×œ-Node.js ××• ×œ×’×¨×¡××•×ª Node.js.\n\n×× ×™ ××§×•×•×” ×©×–×” ×¢×•×–×¨! ×”×× ×™×© ×œ×š ×©××œ×•×ª × ×•×¡×¤×•×ª?<end_of_turn>\n<start_of_turn>user\n××” ×”×’×¨×¡× ×”×—×“×©×” ×©×œ node?<end_of_turn>\n<start_of_turn>model\n× ×›×•×Ÿ ×œ×¢×›×©×™×• (19 ×‘××•×§×˜×•×‘×¨ 2023), ×”×’×¨×¡×” ×”×™×¦×™×‘×” ×”×¢×“×›× ×™×ª ×‘×™×•×ª×¨ ×©×œ Node.js ×”×™× **v20.5.0**.\n\n×¢× ×–××ª, ×—×©×•×‘ ×œ×¦×™×™×Ÿ ×©-Node.js ×¢×•×‘×¨×ª ×¢×“×›×•× ×™× ×ª×›×•×¤×™×. ×œ×›×Ÿ, ×›×“×™ ×œ×§×‘×œ ××ª ×”××™×“×¢ ×”××“×•×™×§ ×‘×™×•×ª×¨, ××•××œ×¥ ×œ×‘×“×•×§ ×‘××ª×¨ ×”×¨×©××™: [https://nodejs.org/en/download/](https://nodejs.org/en/download/)\n\n××ª×¨ ×–×” ×™×¡×¤×§ ××ª ×”×’×¨×¡×” ×”×¢×“×›× ×™×ª ×‘×™×•×ª×¨, ×›×•×œ×œ ×’×¨×¡××•×ª Long Term Support (LTS) ×©×™×© ×œ×”×Ÿ ×ª××™×›×” ××¨×•×›×ª ×˜×•×•×—.<end_of_turn>\n<start_of_turn>user\n××’×™×“ ×œ×š ××” ×”×‘×¢×™×”, ×× ×™ ×¨×•×¦×” ×œ×”×¨×™×¥ ××ª ×”×¤×¨×•×™×§×˜ ×©×œ×™ ××‘×œ ×”×•× ×œ× ××–×”×” ××ª ×”××™×œ×” npm ×•×× ×™ ×¨×•××” ×©node ××•×ª×§×Ÿ ×¢×œ ×”××—×©×‘, ××– ××” ×¢×•×“ ×™×›×•×œ ×œ×”×™×•×ª ×”×¡×™×‘×” ×œ×›×š?<end_of_turn>\n<start_of_turn>model\n××•×§×™×™, ×”×‘× ×ª×™. ×”×¢×•×‘×“×” ×©-Node.js ××•×ª×§×Ÿ ×œ× ×‘×”×›×¨×— ××•××¨×ª ×©-npm ×–××™×Ÿ ×‘× ×ª×™×‘ ×”××¢×¨×›×ª ×©×œ×š. ×”× ×” ×›××” ×¡×™×‘×•×ª ××¤×©×¨×™×•×ª ×•×¤×ª×¨×•× ×•×ª:\n\n1.  **npm ×œ× ××•×ª×§×Ÿ ×›×—×œ×§ ××”×”×ª×§× ×” ×©×œ Node.js:** ×‘×¢×‘×¨, npm ×œ× ×”×•×ª×§×Ÿ ××•×˜×•××˜×™×ª ×¢× Node.js, ××‘×œ ×›×™×•× ×–×” ×××•×¨ ×œ×§×¨×•×ª. ×¢× ×–××ª, ×™×© ×¡×™×›×•×™ ×©×”×”×ª×§× ×” ×œ× ×”×•×©×œ××” ×›×¨××•×™.\n\n    *   **×¤×ª×¨×•×Ÿ:** × ×¡×” ×œ×”×ª×§×™×Ÿ ××—×“×© ××ª Node.js. ×•×“× ×©×‘×–××Ÿ ×”×”×ª×§× ×” ××¡×•××Ÿ ×”××¤×©×¨×•×ª ×œ×”×ª×§×™×Ÿ npm. ××ª×” ×™×›×•×œ ×œ×”×•×¨×™×“ ××ª ×”-installer ×××ª×¨ Node.js: [https://nodejs.org/en/download/](https://nodejs.org/en/download/)\n\n2.  **npm ×œ× × ××¦× ×‘× ×ª×™×‘ ×”××¢×¨×›×ª (PATH):** ×”×˜×¨××™× ×œ ×¦×¨×™×š ×œ×“×¢×ª ××™×¤×” ×œ××¦×•× ××ª npm. ×× ×”×•× ×œ× × ××¦× ×‘× ×ª×™×‘ (PATH), ×”×•× ×œ× ×™×–×”×” ××ª ×”×¤×§×•×“×”.\n\n    *   **×¤×ª×¨×•×Ÿ (Windows):**\n        *   ×¤×ª×— ××ª "×”×’×“×¨×•×ª ××¢×¨×›×ª ××ª×§×“××•×ª" (System Properties) (× ×™×ª×Ÿ ×œ×—×¤×© "System Properties" ×‘×ª×¤×¨×™×˜ ×”×”×ª×—×œ×”).\n        *   ×œ×—×¥ ×¢×œ "×¡×‘×™×‘×”" (Environment).\n        *   ×ª×—×ª "××©×ª× ×™ ××¢×¨×›×ª" (System variables), ××ª×¨ ××ª ×”××©×ª× ×” "Path" ×•×‘×—×¨ "×¢×¨×•×š" (Edit).\n        *   ×”×•×¡×£ ××ª ×”× ×ª×™×‘ ×œ×¡×¤×¨×™×™×ª npm. ×‘×“×¨×š ×›×œ×œ ×–×” ××©×”×• ×›××• `C:\\Program Files\\nodejs`.\n        *   ××—×¨×™ ×©××™×¨×ª ×”×©×™× ×•×™×™×, ×¡×’×•×¨ ×•×¤×ª×— ××—×“×© ××ª ×”×˜×¨××™× ×œ.\n    *   **×¤×ª×¨×•×Ÿ (macOS/Linux):**\n        *   ×¢×¨×•×š ××ª ×§×•×‘×¥ ×”-profile ×©×œ ×”××©×ª××© ×©×œ×š (×œ×¨×•×‘ `~/.bashrc`, `~/.zshrc` ××• `~/.profile`).\n        *   ×”×•×¡×£ ××ª ×”×©×•×¨×” ×”×‘××”, ×ª×•×š ×”×ª×××ª ×”× ×ª×™×‘ ×‘××™×“×ª ×”×¦×•×¨×š: `export PATH="$PATH:/usr/local/bin"` (××• × ×ª×™×‘ ××—×¨ ×× npm ××•×ª×§×Ÿ ×‘××™×§×•× ×©×•× ×”).\n        *   ×©××•×¨ ××ª ×”×§×•×‘×¥ ×•×”×¤×¢×œ ××•×ª×• ×‘×××¦×¢×•×ª ×”×¤×§×•×“×” `source ~/.bashrc` (××• ×”×¤×§×•×“×” ×”××ª××™××” ×¢×‘×•×¨ ×”-profile ×©×œ×š).\n\n3.  **×”×ª×§× ×” ×¤×’×•××” ×©×œ npm:** ×™×™×ª×›×Ÿ ×©×”×”×ª×§× ×” ×©×œ npm ×”×ª×§×œ×§×œ×”.\n\n    *   **×¤×ª×¨×•×Ÿ:**\n        *   × ×¡×” ×œ×”×¡×™×¨ ××ª npm ×•×œ×”×ª×§×™×Ÿ ××•×ª×• ××—×“×©. × ×™×ª×Ÿ ×œ×¢×©×•×ª ×–××ª ×‘×××¦×¢×•×ª Node Package Manager ×¢×¦××• (×× ××ª×” ××¦×œ×™×— ×œ×’×©×ª ××œ×™×• ×‘×“×¨×š ×›×œ×©×”×™).\n        *   ×× ×”×›×œ × ×›×©×œ, × ×¡×” ×œ×”×ª×§×™×Ÿ ×’×¨×¡×” ×¡×¤×¦×™×¤×™×ª ×©×œ npm (×œ×“×•×’××”, ×’×¨×¡×” ×™×©× ×” ×™×•×ª×¨) ×‘×××¦×¢×•×ª npm ×¢×¦××• (×™×™×ª×›×Ÿ ×©×ª×¦×˜×¨×š ×œ×”×©×ª××© ×‘×× ×”×œ ×—×‘×™×œ×•×ª ××—×¨ ×–×× ×™×ª).\n\n4.  **×‘×¢×™×™×ª ×”×¨×©××•×ª:** ×™×™×ª×›×Ÿ ×©××™×Ÿ ×œ×š ×”×¨×©××•×ª ××¡×¤×™×§×•×ª ×›×“×™ ×œ×’×©×ª ×œ-npm.\n\n    *   **×¤×ª×¨×•×Ÿ (Windows):** ×”×¤×¢×œ ××ª ×”×˜×¨××™× ×œ ×›×× ×”×œ (Run as administrator).\n    *   **×¤×ª×¨×•×Ÿ (macOS/Linux):** ×•×“× ×©××©×ª××© ×”××¢×¨×›×ª ×©×œ×š ×”×•× ×‘×¢×œ ×”×¨×©××•×ª ××ª××™××•×ª ×œ×¡×¤×¨×™×•×ª ×©×‘×”×Ÿ ××•×ª×§×Ÿ npm.\n\n5. **×”×˜×¨××™× ×œ ×œ× ××¨×™×¥ ××ª ×”×¤×§×•×“×” ×‘×¡×¤×¨×™×™×” ×”× ×›×•× ×”:**  ××¤×™×œ×• ×× npm ××•×ª×§×Ÿ, ×× ××ª×” ×œ× ××¨×™×¥ ××ª ×”×¤×§×•×“×” ×‘×¡×¤×¨×™×™×” ×©××›×™×œ×” ××ª ×”×¤×¨×•×™×§×˜ ×©×œ×š ××• ××ª ×”×§×•×‘×¥ `package.json`, ×™×™×ª×›×Ÿ ×©×”×˜×¨××™× ×œ ×œ× ×™×–×”×” ××ª npm ×›×—×œ×§ ××”×ª×œ×•×ª ×©×œ ×”×¤×¨×•×™×§×˜.\n\n    * **×¤×ª×¨×•×Ÿ:**  ×•×“× ×©××ª×” × ××¦× ×‘×¡×¤×¨×™×™×” ×”× ×›×•× ×” ×‘×˜×¨××™× ×œ ×œ×¤× ×™ ×©××ª×” ××¨×™×¥ ××ª ×”×¤×§×•×“×” `npm`.\n\n**×˜×™×¤ × ×•×¡×£:** × ×¡×” ×œ×”×¨×™×¥ ××ª ×”×¤×§×•×“×” `where node` ××• `which node` (×ª×œ×•×™ ×‘××¢×¨×›×ª ×”×”×¤×¢×œ×” ×©×œ×š). ×–×” ×™×¦×™×’ ××ª ×”× ×ª×™×‘ ×”××œ× ×©×œ Node.js. ×œ××—×¨ ××›×Ÿ, ×—×¤×© ×¡×¤×¨×™×™×” ×§×¨×•×‘×” ×‘×©× `npm` ×•×‘×“×•×§ ×× ×”×™× ×§×™×™××ª ×‘× ×ª×™×‘ ×”-PATH ×©×œ×š.\n\n×× ×™ ××§×•×•×” ×©×”×˜×™×¤×™× ×”××œ×” ×™×¢×–×¨×• ×œ×š ×œ×¤×ª×•×¨ ××ª ×”×‘×¢×™×”! ×× ×¢×“×™×™×Ÿ ×™×© ×œ×š ×§×•×©×™, ×¤×¨×˜ ×™×•×ª×¨ ×¢×œ ××¢×¨×›×ª ×”×”×¤×¢×œ×” ×©×œ×š ×•××” ×‘×“×™×•×§ ××ª×” ×¨×•××” ×‘×˜×¨××™× ×œ.<end_of_turn>\n<start_of_turn>user\n×™×© ×œ×™ ×’×¨×¡× 18.0.0<end_of_turn>\n<start_of_turn>model\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=0.95, top_k=64, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=129015, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None, extra_args=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:40794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-09 09:59:01 [async_llm.py:228] Added request chatcmpl-c28eef6b83744dc88c8339de69bd54c3.
INFO:     127.0.0.1:47236 - "GET /metrics HTTP/1.1" 200 OK
INFO 07-09 09:59:07 [loggers.py:87] Engine 000: Avg prompt throughput: 205.7 tokens/s, Avg generation throughput: 38.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 09:59:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 09:59:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 09:59:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 09:59:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 09:59:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:00:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:01:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:02:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:03:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:04:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:05:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:06:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:07:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:08:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:09:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:10:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:11:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:12:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:13:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:14:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:15:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:16:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:17:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:18:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:19:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:20:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:21:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:22:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:23:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:24:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:25:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:26:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:27:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:28:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:29:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:30:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:31:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:32:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:33:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:34:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:35:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:36:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:37 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:47 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:37:57 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:07 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:17 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:27 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:38 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:48 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:38:58 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:39:08 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:39:18 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:39:28 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
INFO 07-09 10:39:38 [loggers.py:87] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 94.6%
